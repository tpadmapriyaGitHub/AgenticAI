{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpadmapriyaGitHub/AgenticAI/blob/Training/Custom_tokenizer_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#USE CASE: CUSTOM TOKENIZER\n",
        "\n",
        "This notebook implements a custom tokenizer using the tiktoken library, likely for processing and visualizing how text input is tokenized based on a specific encoding model (cl100k_base). The use case involves taking a userâ€™s input text, converting it into tokens, and then displaying these tokens in a color-coded manner for easy interpretation. This is useful for understanding how text is broken down into tokens, which is critical for Natural Language Processing (NLP) tasks such as language modeling, text generation, and machine learning workflows. Additionally, the code counts the number of tokens and characters in the tokenized output, providing insights into text compression and processing efficiency, which can be valuable in optimizing AI models or other text-based algorithms.\n",
        "\n",
        "##Tech Stack:\n",
        "\n",
        "1. Python 3.11.1\n",
        "2. tiktoken library (for tokenization)\n",
        "3. IPython (for output control)\n",
        "4. Jupyter Notebook (as the development environment)\n",
        "5. ANSI escape codes (for color-coded terminal output)\n"
      ],
      "metadata": {
        "id": "-mf1Im65MCQg"
      },
      "id": "-mf1Im65MCQg"
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Library Imports and Setup"
      ],
      "metadata": {
        "id": "-vufEAcIIvXW"
      },
      "id": "-vufEAcIIvXW"
    },
    {
      "cell_type": "code",
      "source": [
        "#install tiktoken\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "KPNN-lk_eRX3",
        "outputId": "33b8f3df-b24f-4217-f520-b9a969525591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KPNN-lk_eRX3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer Initialization and User Input Handling"
      ],
      "metadata": {
        "id": "afXWmiSDJILV"
      },
      "id": "afXWmiSDJILV"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c84fbec2-e7c0-4178-8fa1-b52aa8b43218",
      "metadata": {
        "id": "c84fbec2-e7c0-4178-8fa1-b52aa8b43218",
        "outputId": "77449d8c-db4c-456d-d650-655af038ca20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text hereTokenization class today\n",
            "[3404, 2065, 538, 3432]\n"
          ]
        }
      ],
      "source": [
        "#Define the tokenizer for encoding & subsequent decoding of tokens in the user's input sentence\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "user_input= input(\"Enter the text here\")\n",
        "\n",
        "tokens=tokenizer.encode(user_input)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6aa59a0c-f35f-4ad3-ae7c-0e4ad9d4da88",
      "metadata": {
        "id": "6aa59a0c-f35f-4ad3-ae7c-0e4ad9d4da88",
        "outputId": "1b2653e3-60d8-420e-ea0c-75952aa8d50a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization class today\n"
          ]
        }
      ],
      "source": [
        "#Decoding\n",
        "decode = tokenizer.decode(tokens)\n",
        "print(decode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "63930a07-a3ea-4976-b437-6a0ede76da55",
      "metadata": {
        "id": "63930a07-a3ea-4976-b437-6a0ede76da55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c1ee32-aabe-4282-8885-4a2b1c91cbb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization class today\n",
            "[3404, 2065, 538, 3432]\n",
            "[b'Token', b'ization', b' class', b' today']\n"
          ]
        }
      ],
      "source": [
        "#Same process is repeated\n",
        "user_input =input(\"\")\n",
        "tokens= tokenizer.encode(user_input)\n",
        "decode_to_bytes =tokenizer.decode_tokens_bytes(tokens)\n",
        "\n",
        "print(tokens)\n",
        "print(decode_to_bytes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token and Character Count Calculation"
      ],
      "metadata": {
        "id": "QzvlqbBgJbwS"
      },
      "id": "QzvlqbBgJbwS"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4752498d-6913-468a-b90a-01cabc1ffe6c",
      "metadata": {
        "id": "4752498d-6913-468a-b90a-01cabc1ffe6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c654560-a19c-41ab-be0b-b276b3de11a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;47;1mToken\u001b[0m\u001b[0;42;1mization\u001b[0m\u001b[0;43;1m class\u001b[0m\u001b[0;44;1m today\u001b[0m\n",
            "\n",
            "['Token', 'ization', ' class', ' today']\n",
            "\n",
            "[3404, 2065, 538, 3432]\n",
            "\n",
            "Token Count: 4\n",
            "Characters: 24\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Initialize tokenizer and variables\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "count = 0\n",
        "token_list = []\n",
        "\n",
        "user_input = input(\"\")\n",
        "clear_output(wait=True)\n",
        "\n",
        "# Encode input and decode tokens\n",
        "encode = tokenizer.encode(user_input)\n",
        "decode = tokenizer.decode_tokens_bytes(encode)\n",
        "\n",
        "# Store decoded tokens as strings\n",
        "for token in decode:\n",
        "    token_list.append(token.decode())\n",
        "\n",
        "# Calculate character count and token length\n",
        "character_count = sum(len(i) for i in token_list)\n",
        "length = len(encode)\n",
        "\n",
        "# Print tokens with alternating color codes\n",
        "for tk in token_list:\n",
        "    if count == 0:\n",
        "        print('\\x1b[0;47;1m' + tk + '\\x1b[0m', end='')\n",
        "    elif count == 1:\n",
        "        print('\\x1b[0;42;1m' + tk + '\\x1b[0m', end='')\n",
        "    elif count == 2:\n",
        "        print('\\x1b[0;43;1m' + tk + '\\x1b[0m', end='')\n",
        "    elif count == 3:\n",
        "        print('\\x1b[0;44;1m' + tk + '\\x1b[0m', end='')\n",
        "    elif count == 4:\n",
        "        print('\\x1b[0;46;1m' + tk + '\\x1b[0m', end='')\n",
        "    elif count == 5:\n",
        "        print('\\x1b[0;45;1m' + tk + '\\x1b[0m', end='')\n",
        "        count = -1\n",
        "    count += 1\n",
        "\n",
        "# Print token details\n",
        "print(\"\\n\\n\" + str(token_list) + \"\\n\")\n",
        "print(str(encode) + \"\\n\")\n",
        "print(\"Token Count: \" + str(length))\n",
        "print(\"Characters: \" + str(character_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1d22e3a2-b549-41c6-bd82-7fb74599f160",
      "metadata": {
        "id": "1d22e3a2-b549-41c6-bd82-7fb74599f160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bc9979-3d13-4139-ff4e-a73034cb8020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;47;1mToken\u001b[0m\u001b[0;42;1mization\u001b[0m\u001b[0;43;1m class\u001b[0m\u001b[0;44;1m today\u001b[0m\n",
            "\n",
            "['Token', 'ization', ' class', ' today']\n",
            "\n",
            "[3404, 2065, 538, 3432]\n",
            "\n",
            "Token Count: 4\n",
            "Characters: 24\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Initialize tokenizer and color codes\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "color_codes = ['0;47', '0;42', '0;43', '0;44', '0;46', '0;45']\n",
        "\n",
        "user_input = input(\"\")\n",
        "clear_output(wait=True)\n",
        "\n",
        "# Encode and decode input\n",
        "encoded = tokenizer.encode(user_input)\n",
        "decoded = tokenizer.decode_tokens_bytes(encoded)\n",
        "token_list = [token.decode() for token in decoded]\n",
        "\n",
        "# Calculate character count\n",
        "character_count = sum(len(i) for i in token_list)\n",
        "\n",
        "# Print tokens with alternating color codes\n",
        "for idx, token in enumerate(token_list):\n",
        "    print(f'\\x1b[{color_codes[idx % len(color_codes)]};1m{token}\\x1b[0m', end='')\n",
        "\n",
        "# Print token details\n",
        "print(\"\\n\\n\" + str(token_list) + \"\\n\")\n",
        "print(str(encoded) + \"\\n\")\n",
        "print(\"Token Count: \" + str(len(encoded)))\n",
        "print(\"Characters: \" + str(character_count))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}